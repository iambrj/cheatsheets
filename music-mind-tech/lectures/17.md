---
author : Bharathi Ramana Joshi
title : Music, Mind and Technology - Lecture 17 notes
date : 12/03/2021
---

- Complexity vs interpretability
- Medawar zone
- Machine learning data types : acoustic to semantic
- Listener responses : perceptual, corporeal, neural responses
- Demographic
- Five studies
    + Predict emotion from audio
    + Organize mood and genre tags
    + Predict musical features from brain responses
    + Predict musical training from brain responses
    + Predict genre and identity from dance kinematics
- Feature selection
    + Feature selection \& extraction : music theoretical and statistical.
        Examples:
            * Low-level : Brightness
            * Mid-level : Pulse clarity
            * High-level : Key
- Vector space modelling over tags and tracks
- Brain as a distributed system
- fMRI decoding : overfitting
- Subject-level encoding, group-level statistical modeling, region-wise evidence
    estimation, region selection, linear classifier
- Genre and personality interacting with dancing styles
